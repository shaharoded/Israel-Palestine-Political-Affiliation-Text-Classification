{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yi5VNBSOv-kT"
   },
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UD9uGUUSvuxq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\amita\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\amita\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\amita\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "from classifiers import *\n",
    "from dataset import TextDataset, get_dataloader\n",
    "from embedder import Embedder\n",
    "from Config.dataset_config import *\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75rhsfaiwuOx"
   },
   "source": [
    "# Define optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Custom tqdm callback\n",
    "class TqdmCallback:\n",
    "    def __init__(self, n_trials):\n",
    "        self.pbar = tqdm(total=n_trials)\n",
    "\n",
    "    def __call__(self, study, trial):\n",
    "        self.pbar.update(1)\n",
    "\n",
    "    def close(self):\n",
    "        self.pbar.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model_hyperparameters = {   # TODO: Add neural network hyperparameters\n",
    "    'logistic_regression': {\n",
    "        'C': (1e-4, 1e2, 'loguniform'),\n",
    "        'max_iter': ([50, 200], 'uniform'),\n",
    "    },\n",
    "    'svm': {\n",
    "        'C': (1e-4, 1e2, 'loguniform'),\n",
    "        'kernel': (['linear', 'poly', 'rbf', 'sigmoid'], 'categorical'),\n",
    "        'degree': (2, 5, 'int'),\n",
    "        'gamma': (['scale', 'auto'], 'categorical')\n",
    "    },\n",
    "    'xgboost': {\n",
    "        'n_estimators': ([5, 100], 'int'),\n",
    "        'learning_rate': ([1e-3, 1.0], 'loguniform'),\n",
    "        'booster': (['gbtree', 'gblinear', 'dart'], 'categorical'),\n",
    "    },\n",
    "    'dnn': {\n",
    "        \"num_epochs\": ([10, 50], 'uniform'),  # Adjust after trial and error\n",
    "        \"learning_rate\": ([1e-3, 0.1], 'loguniform'),\n",
    "        \"batch_norm\": ([True, False], 'categorical'),\n",
    "        \"drop_out\": ([0.0, 1.0], 'uniform'),\n",
    "        \"layers\": ([[768, 64, 64, 3],\n",
    "                    [768, 128, 64, 3],\n",
    "                    [768, 512, 32, 3],\n",
    "                    [768, 512, 128, 3]], 'custom')  # Layer dimensions, including an input and and output layer.\n",
    "    }\n",
    "}\n",
    "\n",
    "def suggest_hyperparameters(trial, hyperparams):\n",
    "    params = {}\n",
    "    for key, value in hyperparams.items():\n",
    "        if len(value) == 2 and value[1] == 'categorical':\n",
    "            params[key] = trial.suggest_categorical(key, value[0])\n",
    "        elif len(value) == 3:\n",
    "            if value[2] == 'loguniform':\n",
    "                params[key] = trial.suggest_float(key, value[0], value[1], log=True)\n",
    "            elif value[2] == 'uniform':\n",
    "                params[key] = trial.suggest_float(key, value[0], value[1])\n",
    "            elif value[2] == 'int':\n",
    "                params[key] = trial.suggest_int(key, value[0], value[1])\n",
    "            elif value[2] == 'categorical':\n",
    "                params[key] = trial.suggest_categorical(key, value[0])\n",
    "            elif value[1] == 'custom':\n",
    "                hidden_dims = params['hidden_dims']\n",
    "                layer_count = len(hidden_dims)\n",
    "                params[key] = trial.suggest_categorical(key, value[0][layer_count])\n",
    "            else:\n",
    "                raise ValueError(f\"Hyperparameter tuple for {key} is not in the expected format: {value}\")\n",
    "    return params\n",
    "\n",
    "# Define objective function for optuna. The function include all models, and should be called with the model name. The function optimize the Classifier class hyperparameters.\n",
    "def objective(trial, model_name, data, folds_scores):\n",
    "    params = suggest_hyperparameters(trial, model_hyperparameters[model_name])\n",
    "\n",
    "    # Add some more parameters for Logistic Regression\n",
    "    if model_name == 'Logistic Regression':\n",
    "        penalty = trial.suggest_categorical('penalty', ['l1', 'l2', None, 'elasticnet'])\n",
    "        if penalty == 'elasticnet':\n",
    "            l1_ratio = trial.suggest_float('l1_ratio', 0.0, 1.0, step=0.25)\n",
    "        else:\n",
    "            l1_ratio = None\n",
    "        params['penalty'] = penalty\n",
    "        params['l1_ratio'] = l1_ratio\n",
    "\n",
    "    # Add some more parameters for XGBoost\n",
    "    elif model_name == 'xgboost':\n",
    "        if params[\"booster\"] in [\"gbtree\", \"dart\"]:\n",
    "            # maximum depth of the tree, signifies complexity of the tree.\n",
    "            params[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 9, step=2)\n",
    "            # minimum child weight, larger the term more conservative the tree.\n",
    "            params[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n",
    "            params[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
    "            # defines how selective algorithm is.\n",
    "            params[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
    "            params[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "\n",
    "        if params[\"booster\"] == \"dart\":\n",
    "            params[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n",
    "            params[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n",
    "            params[\"rate_drop\"] = trial.suggest_float(\"rate_drop\", 1e-8, 1.0, log=True)\n",
    "            params[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 1e-8, 1.0, log=True)\n",
    "\n",
    "\n",
    "    model = Classifier(params, model_type=model_name)\n",
    "    model.fit(data)\n",
    "\n",
    "    # Create a pipeline with just the classifier since feature prep is external\n",
    "    pipeline = Pipeline([\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "\n",
    "    # Define the cross-validation strategy\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform cross-validation and return the mean F1 score\n",
    "    scores = cross_val_score(pipeline, data, cv=cv, scoring='f1')\n",
    "    folds_scores.append(scores)\n",
    "    return scores.mean()\n",
    "\n",
    "def optimize_model(model_name, data, n_trials=50, timout=1200):\n",
    "    \"\"\"\n",
    "    The actual optimization.\n",
    "    \"\"\"\n",
    "    folds_scores = []   # create a list to store the scores from each trial folds\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    progress_bar = TqdmCallback(n_trials)\n",
    "    study.optimize(lambda trial: objective(trial, model_name, data, folds_scores), n_trials=n_trials, timeout=timout, callbacks=[progress_bar])\n",
    "    # Close progress bar\n",
    "    progress_bar.close()\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_value = study.best_value\n",
    "\n",
    "    print(f\"Best hyperparameters for {model_name}: {best_params}\")\n",
    "    print(f\"Best F1 score for {model_name}: {best_value}\")\n",
    "\n",
    "    return best_params, best_value, folds_scores\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Optimize models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7ekXAYOkw0w_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset Status]: Loading the dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing comments: 100%|██████████| 6637/6637 [00:00<00:00, 22131.32it/s]\n",
      "Augmenting data: 100%|██████████| 6537/6537 [00:00<00:00, 13063.91row/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataset Status]: Loading the dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing comments: 100%|██████████| 6637/6637 [00:00<00:00, 27790.46it/s]\n",
      "Augmenting data: 100%|██████████| 6537/6537 [00:15<00:00, 414.30row/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dataloader Status]: Loading the dataset...\n",
      "[Dataloader Status]: Done.\n",
      "[Dataloader Status]: Loading the dataset...\n",
      "[Dataloader Status]: Done.\n",
      "[Dataloader Status]: Loading the dataset...\n",
      "[Dataloader Status]: Done.\n",
      "[Dataloader Status]: Loading the dataset...\n",
      "[Dataloader Status]: Done.\n"
     ]
    }
   ],
   "source": [
    "# Create 4 different datasets: embedding with and without augmentation, and tf-idf with and without augmentation.\n",
    "embedder = Embedder()\n",
    "data_without_augmentation = TextDataset(\n",
    "    data_path=DATA_PATH,\n",
    "    subset=SUBSET,\n",
    "    id_column_idx=ID_COLUMN_IDX,\n",
    "    comment_column_idx=COMMENT_COLUMN_IDX,\n",
    "    label_column_idx=LABEL_COLUMN_IDX,\n",
    "    subset_column_idx=SUBSET_COLUMN_IDX,\n",
    "    augmented_classes=AUGMENTED_CLASSES,\n",
    "    augmentation_ratio=0,\n",
    "    augmentation_methods=AUGMENTATION_METHODS,\n",
    "    adversation_ratio = ADVERSATION_RATIO\n",
    ")\n",
    "\n",
    "data_with_augmentation = TextDataset(\n",
    "    data_path=DATA_PATH,\n",
    "    subset=SUBSET,\n",
    "    id_column_idx=ID_COLUMN_IDX,\n",
    "    comment_column_idx=COMMENT_COLUMN_IDX,\n",
    "    label_column_idx=LABEL_COLUMN_IDX,\n",
    "    subset_column_idx=SUBSET_COLUMN_IDX,\n",
    "    augmented_classes=AUGMENTED_CLASSES,\n",
    "    augmentation_ratio=AUGMENTATION_RATIO,\n",
    "    augmentation_methods=AUGMENTATION_METHODS,\n",
    "    adversation_ratio = ADVERSATION_RATIO\n",
    ")\n",
    "\n",
    "bert_embedding_no_augmentation_loader = get_dataloader(\n",
    "    dataset=data_without_augmentation,\n",
    "    embedder=embedder,\n",
    "    datashape='embedding',\n",
    "    embedding_method=EMBEDDING_METHOD,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "bert_embedding_with_augmentation_loader = get_dataloader(\n",
    "    dataset=data_with_augmentation,\n",
    "    embedder=embedder,\n",
    "    datashape='embedding',\n",
    "    embedding_method=EMBEDDING_METHOD,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "tfidf_embedding_no_augmentation_loader = get_dataloader(\n",
    "    dataset=data_without_augmentation,\n",
    "    embedder=embedder,\n",
    "    datashape='embedding',\n",
    "    embedding_method='tf-idf',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "tfidf_embedding_with_augmentation_loader = get_dataloader(\n",
    "    dataset=data_with_augmentation,\n",
    "    embedder=embedder,\n",
    "    datashape='embedding',\n",
    "    embedding_method='tf-idf',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-16 23:52:42,982] A new study created in memory with name: no-name-effe6d67-5e66-4119-8a67-232d534c35c5\n",
      "  0%|          | 0/50 [00:00<?, ?it/s][W 2025-01-16 23:58:39,835] Trial 0 failed with parameters: {'C': 22.794596961691315} because of the following error: TypeError('expected Tensor as element 0 in argument 0, but got tuple').\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\amita\\PycharmProjects\\Israel-Palestine-Political-Affiliation-Text-Classification\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\amita\\AppData\\Local\\Temp\\ipykernel_2360\\3548785863.py\", line 107, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, model_name, data, folds_scores), n_trials=n_trials, timeout=timout, callbacks=[progress_bar])\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\amita\\AppData\\Local\\Temp\\ipykernel_2360\\3548785863.py\", line 85, in objective\n",
      "    model.fit(data)\n",
      "  File \"C:\\Users\\amita\\PycharmProjects\\Israel-Palestine-Political-Affiliation-Text-Classification\\classifiers.py\", line 98, in fit\n",
      "    y = torch.cat(y).numpy()\n",
      "        ^^^^^^^^^^^^\n",
      "TypeError: expected Tensor as element 0 in argument 0, but got tuple\n",
      "[W 2025-01-16 23:58:39,863] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got tuple",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m lr_results \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m----> 2\u001B[0m lr_results[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbert_without_augmentation\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43moptimize_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlogistic_regression\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbert_embedding_no_augmentation_loader\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[3], line 107\u001B[0m, in \u001B[0;36moptimize_model\u001B[1;34m(model_name, data, n_trials, timout)\u001B[0m\n\u001B[0;32m    105\u001B[0m study \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study(direction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmaximize\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    106\u001B[0m progress_bar \u001B[38;5;241m=\u001B[39m TqdmCallback(n_trials)\n\u001B[1;32m--> 107\u001B[0m \u001B[43mstudy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mobjective\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfolds_scores\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    108\u001B[0m \u001B[38;5;66;03m# Close progress bar\u001B[39;00m\n\u001B[0;32m    109\u001B[0m progress_bar\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\PycharmProjects\\Israel-Palestine-Political-Affiliation-Text-Classification\\venv\\Lib\\site-packages\\optuna\\study\\study.py:475\u001B[0m, in \u001B[0;36mStudy.optimize\u001B[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m    373\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21moptimize\u001B[39m(\n\u001B[0;32m    374\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    375\u001B[0m     func: ObjectiveFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    382\u001B[0m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    383\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    384\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[0;32m    385\u001B[0m \n\u001B[0;32m    386\u001B[0m \u001B[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    473\u001B[0m \u001B[38;5;124;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[0;32m    474\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 475\u001B[0m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    476\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    477\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    478\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    479\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    480\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    481\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    482\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    483\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    484\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    485\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Israel-Palestine-Political-Affiliation-Text-Classification\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001B[0m, in \u001B[0;36m_optimize\u001B[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     62\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 63\u001B[0m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     64\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     65\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     67\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     68\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     69\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     70\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     72\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     74\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     75\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     76\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\Israel-Palestine-Political-Affiliation-Text-Classification\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001B[0m, in \u001B[0;36m_optimize_sequential\u001B[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[0;32m    157\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 160\u001B[0m     frozen_trial \u001B[38;5;241m=\u001B[39m \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    162\u001B[0m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[0;32m    163\u001B[0m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[0;32m    164\u001B[0m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[0;32m    165\u001B[0m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[0;32m    166\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "File \u001B[1;32m~\\PycharmProjects\\Israel-Palestine-Political-Affiliation-Text-Classification\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    241\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShould not reach.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    243\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    244\u001B[0m     frozen_trial\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m==\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mFAIL\n\u001B[0;32m    245\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    246\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[0;32m    247\u001B[0m ):\n\u001B[1;32m--> 248\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m frozen_trial\n",
      "File \u001B[1;32m~\\PycharmProjects\\Israel-Palestine-Political-Affiliation-Text-Classification\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    195\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial\u001B[38;5;241m.\u001B[39m_trial_id, study\u001B[38;5;241m.\u001B[39m_storage):\n\u001B[0;32m    196\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 197\u001B[0m         value_or_values \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    198\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mTrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    199\u001B[0m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[0;32m    200\u001B[0m         state \u001B[38;5;241m=\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mPRUNED\n",
      "Cell \u001B[1;32mIn[3], line 107\u001B[0m, in \u001B[0;36moptimize_model.<locals>.<lambda>\u001B[1;34m(trial)\u001B[0m\n\u001B[0;32m    105\u001B[0m study \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study(direction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmaximize\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    106\u001B[0m progress_bar \u001B[38;5;241m=\u001B[39m TqdmCallback(n_trials)\n\u001B[1;32m--> 107\u001B[0m study\u001B[38;5;241m.\u001B[39moptimize(\u001B[38;5;28;01mlambda\u001B[39;00m trial: \u001B[43mobjective\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfolds_scores\u001B[49m\u001B[43m)\u001B[49m, n_trials\u001B[38;5;241m=\u001B[39mn_trials, timeout\u001B[38;5;241m=\u001B[39mtimout, callbacks\u001B[38;5;241m=\u001B[39m[progress_bar])\n\u001B[0;32m    108\u001B[0m \u001B[38;5;66;03m# Close progress bar\u001B[39;00m\n\u001B[0;32m    109\u001B[0m progress_bar\u001B[38;5;241m.\u001B[39mclose()\n",
      "Cell \u001B[1;32mIn[3], line 85\u001B[0m, in \u001B[0;36mobjective\u001B[1;34m(trial, model_name, data, folds_scores)\u001B[0m\n\u001B[0;32m     81\u001B[0m         params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskip_drop\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m trial\u001B[38;5;241m.\u001B[39msuggest_float(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskip_drop\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m1e-8\u001B[39m, \u001B[38;5;241m1.0\u001B[39m, log\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     84\u001B[0m model \u001B[38;5;241m=\u001B[39m Classifier(params, model_type\u001B[38;5;241m=\u001B[39mmodel_name)\n\u001B[1;32m---> 85\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;66;03m# Create a pipeline with just the classifier since feature prep is external\u001B[39;00m\n\u001B[0;32m     88\u001B[0m pipeline \u001B[38;5;241m=\u001B[39m Pipeline([\n\u001B[0;32m     89\u001B[0m     (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclassifier\u001B[39m\u001B[38;5;124m'\u001B[39m, model)\n\u001B[0;32m     90\u001B[0m ])\n",
      "File \u001B[1;32m~\\PycharmProjects\\Israel-Palestine-Political-Affiliation-Text-Classification\\classifiers.py:98\u001B[0m, in \u001B[0;36mClassifier.fit\u001B[1;34m(self, train_loader)\u001B[0m\n\u001B[0;32m     96\u001B[0m         y\u001B[38;5;241m.\u001B[39mappend(labels)\n\u001B[0;32m     97\u001B[0m     X \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat(X)\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[1;32m---> 98\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m     99\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mfit(X, y)\n\u001B[0;32m    100\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdnn\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[1;31mTypeError\u001B[0m: expected Tensor as element 0 in argument 0, but got tuple"
     ]
    }
   ],
   "source": [
    "lr_results = {}\n",
    "lr_results['bert_without_augmentation'] = optimize_model('logistic_regression', bert_embedding_no_augmentation_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-16 21:49:56,833] A new study created in memory with name: no-name-d8e117c0-2438-45a7-9c42-d6e67c163556\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001B[A[W 2025-01-16 21:50:18,034] Trial 0 failed with parameters: {'C': 0.0009880967647562218} because of the following error: ValueError('not enough values to unpack (expected 3, got 2)').\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\amita\\PycharmProjects\\Israel-Palestine-Political-Affiliation-Text-Classification\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\amita\\AppData\\Local\\Temp\\ipykernel_13200\\3548785863.py\", line 107, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, model_name, data, folds_scores), n_trials=n_trials, timeout=timout, callbacks=[progress_bar])\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\amita\\AppData\\Local\\Temp\\ipykernel_13200\\3548785863.py\", line 85, in objective\n",
      "    model.fit(data)\n",
      "  File \"C:\\Users\\amita\\PycharmProjects\\Israel-Palestine-Political-Affiliation-Text-Classification\\classifiers.py\", line 94, in fit\n",
      "    features, labels = batch\n",
      "ValueError: not enough values to unpack (expected 3, got 2)\n",
      "[W 2025-01-16 21:50:18,036] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[33], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m lr_results \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m----> 2\u001B[0m lr_results[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbert_without_augmentation\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43moptimize_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlogistic_regression\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbert_embedding_no_augmentation_loader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m lr_results[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbert_with_augmentation\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m optimize_model(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlogistic_regression\u001B[39m\u001B[38;5;124m'\u001B[39m, bert_embedding_with_augmentation_loader)\n\u001B[0;32m      4\u001B[0m lr_results[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtfidf_without_augmentation\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m optimize_model(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlogistic_regression\u001B[39m\u001B[38;5;124m'\u001B[39m, tfidf_embedding_no_augmentation_loader)\n",
      "Cell \u001B[1;32mIn[29], line 107\u001B[0m, in \u001B[0;36moptimize_model\u001B[1;34m(model_name, data, n_trials, timout)\u001B[0m\n\u001B[0;32m    105\u001B[0m study \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study(direction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmaximize\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    106\u001B[0m progress_bar \u001B[38;5;241m=\u001B[39m TqdmCallback(n_trials)\n\u001B[1;32m--> 107\u001B[0m \u001B[43mstudy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mobjective\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfolds_scores\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    108\u001B[0m \u001B[38;5;66;03m# Close progress bar\u001B[39;00m\n\u001B[0;32m    109\u001B[0m progress_bar\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\PycharmProjects\\Israel-Palestine-Political-Affiliation-Text-Classification\\venv\\Lib\\site-packages\\optuna\\study\\study.py:475\u001B[0m, in \u001B[0;36mStudy.optimize\u001B[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m    373\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21moptimize\u001B[39m(\n\u001B[0;32m    374\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    375\u001B[0m     func: ObjectiveFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    382\u001B[0m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    383\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    384\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[0;32m    385\u001B[0m \n\u001B[0;32m    386\u001B[0m \u001B[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    473\u001B[0m \u001B[38;5;124;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[0;32m    474\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 475\u001B[0m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    476\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    477\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    478\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    479\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    480\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    481\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    482\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    483\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    484\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    485\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Israel-Palestine-Political-Affiliation-Text-Classification\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001B[0m, in \u001B[0;36m_optimize\u001B[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     62\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m---> 63\u001B[0m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     64\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     65\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     66\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     67\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     68\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     69\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     70\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     72\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     74\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     75\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     76\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[1;32m~\\PycharmProjects\\Israel-Palestine-Political-Affiliation-Text-Classification\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001B[0m, in \u001B[0;36m_optimize_sequential\u001B[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[0;32m    157\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 160\u001B[0m     frozen_trial \u001B[38;5;241m=\u001B[39m \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    162\u001B[0m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[0;32m    163\u001B[0m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[0;32m    164\u001B[0m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[0;32m    165\u001B[0m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[0;32m    166\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "File \u001B[1;32m~\\PycharmProjects\\Israel-Palestine-Political-Affiliation-Text-Classification\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:248\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    241\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShould not reach.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    243\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    244\u001B[0m     frozen_trial\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m==\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mFAIL\n\u001B[0;32m    245\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    246\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[0;32m    247\u001B[0m ):\n\u001B[1;32m--> 248\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m frozen_trial\n",
      "File \u001B[1;32m~\\PycharmProjects\\Israel-Palestine-Political-Affiliation-Text-Classification\\venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:197\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    195\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial\u001B[38;5;241m.\u001B[39m_trial_id, study\u001B[38;5;241m.\u001B[39m_storage):\n\u001B[0;32m    196\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 197\u001B[0m         value_or_values \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    198\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mTrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    199\u001B[0m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[0;32m    200\u001B[0m         state \u001B[38;5;241m=\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mPRUNED\n",
      "Cell \u001B[1;32mIn[29], line 107\u001B[0m, in \u001B[0;36moptimize_model.<locals>.<lambda>\u001B[1;34m(trial)\u001B[0m\n\u001B[0;32m    105\u001B[0m study \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study(direction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmaximize\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    106\u001B[0m progress_bar \u001B[38;5;241m=\u001B[39m TqdmCallback(n_trials)\n\u001B[1;32m--> 107\u001B[0m study\u001B[38;5;241m.\u001B[39moptimize(\u001B[38;5;28;01mlambda\u001B[39;00m trial: \u001B[43mobjective\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfolds_scores\u001B[49m\u001B[43m)\u001B[49m, n_trials\u001B[38;5;241m=\u001B[39mn_trials, timeout\u001B[38;5;241m=\u001B[39mtimout, callbacks\u001B[38;5;241m=\u001B[39m[progress_bar])\n\u001B[0;32m    108\u001B[0m \u001B[38;5;66;03m# Close progress bar\u001B[39;00m\n\u001B[0;32m    109\u001B[0m progress_bar\u001B[38;5;241m.\u001B[39mclose()\n",
      "Cell \u001B[1;32mIn[29], line 85\u001B[0m, in \u001B[0;36mobjective\u001B[1;34m(trial, model_name, data, folds_scores)\u001B[0m\n\u001B[0;32m     81\u001B[0m         params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskip_drop\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m trial\u001B[38;5;241m.\u001B[39msuggest_float(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskip_drop\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m1e-8\u001B[39m, \u001B[38;5;241m1.0\u001B[39m, log\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     84\u001B[0m model \u001B[38;5;241m=\u001B[39m Classifier(params, model_type\u001B[38;5;241m=\u001B[39mmodel_name)\n\u001B[1;32m---> 85\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;66;03m# Create a pipeline with just the classifier since feature prep is external\u001B[39;00m\n\u001B[0;32m     88\u001B[0m pipeline \u001B[38;5;241m=\u001B[39m Pipeline([\n\u001B[0;32m     89\u001B[0m     (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclassifier\u001B[39m\u001B[38;5;124m'\u001B[39m, model)\n\u001B[0;32m     90\u001B[0m ])\n",
      "File \u001B[1;32m~\\PycharmProjects\\Israel-Palestine-Political-Affiliation-Text-Classification\\classifiers.py:94\u001B[0m, in \u001B[0;36mClassifier.fit\u001B[1;34m(self, train_loader)\u001B[0m\n\u001B[0;32m     92\u001B[0m X, y \u001B[38;5;241m=\u001B[39m [], []\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[1;32m---> 94\u001B[0m     comment_ids, features, labels \u001B[38;5;241m=\u001B[39m batch\n\u001B[0;32m     95\u001B[0m     X\u001B[38;5;241m.\u001B[39mappend(features)\n\u001B[0;32m     96\u001B[0m     y\u001B[38;5;241m.\u001B[39mappend(labels)\n",
      "\u001B[1;31mValueError\u001B[0m: not enough values to unpack (expected 3, got 2)"
     ]
    }
   ],
   "source": [
    "\n",
    "lr_results['bert_with_augmentation'] = optimize_model('logistic_regression', bert_embedding_with_augmentation_loader)\n",
    "lr_results['tfidf_without_augmentation'] = optimize_model('logistic_regression', tfidf_embedding_no_augmentation_loader)\n",
    "lr_results['tfidf_with_augmentation'] = optimize_model('logistic_regression', tfidf_embedding_with_augmentation_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Logistic Regression results:\\n\\n\")\n",
    "print(f\"Using BERT embeddings without augmentation scores: {lr_results['bert_without_augmentation'][2]}\")\n",
    "print(f\"Using BERT embeddings without augmentation best score: {lr_results['bert_without_augmentation'][1]}\")\n",
    "print(f\"Using BERT embeddings without augmentation best parameters: {lr_results['bert_without_augmentation'][0]}\\n\\n\")\n",
    "print(f\"Using BERT embeddings with augmentation scores: {lr_results['bert_with_augmentation'][2]}\")\n",
    "print(f\"Using BERT embeddings with augmentation best score: {lr_results['bert_with_augmentation'][1]}\")\n",
    "print(f\"Using BERT embeddings with augmentation best parameters: {lr_results['bert_with_augmentation'][0]}\\n\\n\")\n",
    "print(f\"Using TF-IDF embeddings without augmentation scores: {lr_results['tfidf_without_augmentation'][2]}\")\n",
    "print(f\"Using TF-IDF embeddings without augmentation best score: {lr_results['tfidf_without_augmentation'][1]}\")\n",
    "print(f\"Using TF-IDF embeddings without augmentation best parameters: {lr_results['tfidf_without_augmentation'][0]}\\n\\n\")\n",
    "print(f\"Using TF-IDF embeddings with augmentation scores: {lr_results['tfidf_with_augmentation'][2]}\")\n",
    "print(f\"Using TF-IDF embeddings with augmentation best score: {lr_results['tfidf_with_augmentation'][1]}\")\n",
    "print(f\"Using TF-IDF embeddings with augmentation best parameters: {lr_results['tfidf_with_augmentation'][0]}\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "Dvg-ZLIiyunH"
   },
   "outputs": [],
   "source": [
    "svm_results = {}\n",
    "svm_results['bert_without_augmentation'] = optimize_model('svm', bert_embedding_no_augmentation_loader)\n",
    "svm_results['bert_with_augmentation'] = optimize_model('svm', bert_embedding_with_augmentation_loader)\n",
    "svm_results['tfidf_without_augmentation'] = optimize_model('svm', tfidf_embedding_no_augmentation_loader)\n",
    "svm_results['tfidf_with_augmentation'] = optimize_model('svm', tfidf_embedding_with_augmentation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"SVM results:\\n\\n\")\n",
    "print(f\"Using BERT embeddings without augmentation scores: {svm_results['bert_without_augmentation'][2]}\")\n",
    "print(f\"Using BERT embeddings without augmentation best score: {svm_results['bert_without_augmentation'][1]}\")\n",
    "print(f\"Using BERT embeddings without augmentation best parameters: {svm_results['bert_without_augmentation'][0]}\\n\\n\")\n",
    "print(f\"Using BERT embeddings with augmentation scores: {svm_results['bert_with_augmentation'][2]}\")\n",
    "print(f\"Using BERT embeddings with augmentation best score: {svm_results['bert_with_augmentation'][1]}\")\n",
    "print(f\"Using BERT embeddings with augmentation best parameters: {svm_results['bert_with_augmentation'][0]}\\n\\n\")\n",
    "print(f\"Using TF-IDF embeddings without augmentation scores: {svm_results['tfidf_without_augmentation'][2]}\")\n",
    "print(f\"Using TF-IDF embeddings without augmentation best score: {svm_results['tfidf_without_augmentation'][1]}\")\n",
    "print(f\"Using TF-IDF embeddings without augmentation best parameters: {svm_results['tfidf_without_augmentation'][0]}\\n\\n\")\n",
    "print(f\"Using TF-IDF embeddings with augmentation scores: {svm_results['tfidf_with_augmentation'][2]}\")\n",
    "print(f\"Using TF-IDF embeddings with augmentation best score: {svm_results['tfidf_with_augmentation'][1]}\")\n",
    "print(f\"Using TF-IDF embeddings with augmentation best parameters: {svm_results['tfidf_with_augmentation'][0]}\\n\\n\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "ze5Iu-hQyvkX"
   },
   "outputs": [],
   "source": [
    "xgb_results = {}\n",
    "xgb_results['bert_without_augmentation'] = optimize_model('xgboost', bert_embedding_no_augmentation_loader)\n",
    "xgb_results['bert_with_augmentation'] = optimize_model('xgboost', bert_embedding_with_augmentation_loader)\n",
    "xgb_results['tfidf_without_augmentation'] = optimize_model('xgboost', tfidf_embedding_no_augmentation_loader)\n",
    "xgb_results['tfidf_with_augmentation'] = optimize_model('xgboost', tfidf_embedding_with_augmentation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"XGBoost results:\\n\\n\")\n",
    "print(f\"Using BERT embeddings without augmentation scores: {xgb_results['bert_without_augmentation'][2]}\")\n",
    "print(f\"Using BERT embeddings without augmentation best score: {xgb_results['bert_without_augmentation'][1]}\")\n",
    "print(f\"Using BERT embeddings without augmentation best parameters: {xgb_results['bert_without_augmentation'][0]}\\n\\n\")\n",
    "print(f\"Using BERT embeddings with augmentation scores: {xgb_results['bert_with_augmentation'][2]}\")\n",
    "print(f\"Using BERT embeddings with augmentation best score: {xgb_results['bert_with_augmentation'][1]}\")\n",
    "print(f\"Using BERT embeddings with augmentation best parameters: {xgb_results['bert_with_augmentation'][0]}\\n\\n\")\n",
    "print(f\"Using TF-IDF embeddings without augmentation scores: {xgb_results['tfidf_without_augmentation'][2]}\")\n",
    "print(f\"Using TF-IDF embeddings without augmentation best score: {xgb_results['tfidf_without_augmentation'][1]}\")\n",
    "print(f\"Using TF-IDF embeddings without augmentation best parameters: {xgb_results['tfidf_without_augmentation'][0]}\\n\\n\")\n",
    "print(f\"Using TF-IDF embeddings with augmentation scores: {xgb_results['tfidf_with_augmentation'][2]}\")\n",
    "print(f\"Using TF-IDF embeddings with augmentation best score: {xgb_results['tfidf_with_augmentation'][1]}\")\n",
    "print(f\"Using TF-IDF embeddings with augmentation best parameters: {xgb_results['tfidf_with_augmentation'][0]}\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dnn_results = {}\n",
    "dnn_results['bert_without_augmentation'] = optimize_model('dnn', bert_embedding_no_augmentation_loader)\n",
    "dnn_results['bert_with_augmentation'] = optimize_model('dnn', bert_embedding_with_augmentation_loader)\n",
    "dnn_results['tfidf_without_augmentation'] = optimize_model('dnn', tfidf_embedding_no_augmentation_loader)\n",
    "dnn_results['tfidf_with_augmentation'] = optimize_model('dnn', tfidf_embedding_with_augmentation_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"DNN results:\\n\\n\")\n",
    "print(f\"Using BERT embeddings without augmentation scores: {dnn_results['bert_without_augmentation'][2]}\")\n",
    "print(f\"Using BERT embeddings without augmentation best score: {dnn_results['bert_without_augmentation'][1]}\")\n",
    "print(f\"Using BERT embeddings without augmentation best parameters: {dnn_results['bert_without_augmentation'][0]}\\n\\n\")\n",
    "print(f\"Using BERT embeddings with augmentation scores: {dnn_results['bert_with_augmentation'][2]}\")\n",
    "print(f\"Using BERT embeddings with augmentation best score: {dnn_results['bert_with_augmentation'][1]}\")\n",
    "print(f\"Using BERT embeddings with augmentation best parameters: {dnn_results['bert_with_augmentation'][0]}\\n\\n\")\n",
    "print(f\"Using TF-IDF embeddings without augmentation scores: {dnn_results['tfidf_without_augmentation'][2]}\")\n",
    "print(f\"Using TF-IDF embeddings without augmentation best score: {dnn_results['tfidf_without_augmentation'][1]}\")\n",
    "print(f\"Using TF-IDF embeddings without augmentation best parameters: {dnn_results['tfidf_without_augmentation'][0]}\\n\\n\")\n",
    "print(f\"Using TF-IDF embeddings with augmentation scores: {dnn_results['tfidf_with_augmentation'][2]}\")\n",
    "print(f\"Using TF-IDF embeddings with augmentation best score: {dnn_results['tfidf_with_augmentation'][1]}\")\n",
    "print(f\"Using TF-IDF embeddings with augmentation best parameters: {dnn_results['tfidf_with_augmentation'][0]}\\n\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
