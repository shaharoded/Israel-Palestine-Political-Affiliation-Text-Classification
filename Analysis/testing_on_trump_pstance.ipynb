{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "873cc523",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35420839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now working in: C:\\Users\\yonat\\CodeProjects\\Israel-Palestine-Political-Affiliation-Text-Classification\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Start from current path and walk up until we find a known file\n",
    "curr_path = Path().resolve()\n",
    "marker_file = \"requirements.txt\"  # or any other file you know exists in your project root\n",
    "\n",
    "while not (curr_path / marker_file).exists() and curr_path != curr_path.parent:\n",
    "    curr_path = curr_path.parent\n",
    "\n",
    "# Set working directory if found\n",
    "if (curr_path / marker_file).exists():\n",
    "    os.chdir(curr_path)\n",
    "    print(\"Now working in:\", Path.cwd())\n",
    "else:\n",
    "    raise RuntimeError(f\"Project root with {marker_file} not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab65f15",
   "metadata": {},
   "source": [
    "# Cleaning the Original Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e1510c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: Data\\p-stance\\pstance_trump_clean.csv (7,953 rows)\n",
      "real_label  Against-Trump  Pro-Trump\n",
      "split                               \n",
      "TEST                  425        352\n",
      "TRAIN                3425       2937\n",
      "VAL                   440        374\n"
     ]
    }
   ],
   "source": [
    "# # ---- config ----\n",
    "# DATA_DIR = Path(\"Data/p-stance\")\n",
    "# FILES    = {\"TRAIN\": \"train_trump.csv\", \"VAL\": \"val_trump.csv\", \"TEST\": \"test_trump.csv\"}\n",
    "# OUT_CSV  = DATA_DIR / \"pstance_trump_clean.csv\"\n",
    "# SOURCE   = \"P Stance\"\n",
    "\n",
    "# # remove links, mentions, and entire hashtag tokens\n",
    "# URL_TOKEN     = re.compile(r\"(https?://\\S+|www\\.\\S+)\", flags=re.IGNORECASE)\n",
    "# MENTION_TOKEN = re.compile(r\"@\\w+\")\n",
    "# HASHTAG_TOKEN = re.compile(r\"(?<!\\w)#\\w+\")\n",
    "# EMOJI_TOKEN   = re.compile(r\"[\\U0001F1E6-\\U0001F1FF\"\n",
    "#                            r\"\\U0001F300-\\U0001F5FF\"\n",
    "#                            r\"\\U0001F600-\\U0001F64F\"\n",
    "#                            r\"\\U0001F680-\\U0001F6FF\"\n",
    "#                            r\"\\U0001F700-\\U0001F77F\"\n",
    "#                            r\"\\U0001F780-\\U0001F7FF\"\n",
    "#                            r\"\\U0001F800-\\U0001F8FF\"\n",
    "#                            r\"\\U0001F900-\\U0001F9FF\"\n",
    "#                            r\"\\U0001FA00-\\U0001FA6F\"\n",
    "#                            r\"\\u2600-\\u27BF]\", flags=re.UNICODE)\n",
    "# MULTI_SPACE   = re.compile(r\"\\s+\")\n",
    "\n",
    "# def clean_text(s: str) -> str:\n",
    "#     if not isinstance(s, str):\n",
    "#         return \"\"\n",
    "#     s = URL_TOKEN.sub(\" \", s)         # drop URLs (gif/image-only posts become empty)\n",
    "#     s = MENTION_TOKEN.sub(\" \", s)     # drop @handles\n",
    "#     s = HASHTAG_TOKEN.sub(\" \", s)     # drop full hashtags\n",
    "#     s = EMOJI_TOKEN.sub(\" \", s)       # drop emojis/symbols\n",
    "#     s = s.replace(\"\\u200b\", \" \")\n",
    "#     s = MULTI_SPACE.sub(\" \", s).strip()\n",
    "#     return s\n",
    "\n",
    "# # ---- map to your three-label scheme ----\n",
    "# label_map = {\n",
    "#     \"favor\":   \"Pro-Trump\",\n",
    "#     \"favour\":  \"Pro-Trump\",\n",
    "#     \"against\": \"Against-Trump\",\n",
    "#     \"neutral\": \"Undefined\",\n",
    "#     \"neither\": \"Undefined\",\n",
    "#     \"none\":    \"Undefined\",\n",
    "# }\n",
    "\n",
    "# def load_split(path: Path, split_name: str) -> pd.DataFrame:\n",
    "#     df = pd.read_csv(path)\n",
    "#     missing = {\"Tweet\", \"Stance\"} - set(df.columns)\n",
    "#     if missing:\n",
    "#         raise ValueError(f\"Missing columns in {path.name}: {missing}\")\n",
    "\n",
    "#     out = pd.DataFrame({\n",
    "#         \"self_text\": df[\"Tweet\"].astype(str).map(clean_text),\n",
    "#         \"real_label\": df[\"Stance\"].astype(str).str.lower().map(lambda x: label_map.get(x, x)),\n",
    "#         \"source\": SOURCE,\n",
    "#         \"split\": split_name.upper(),\n",
    "#     })\n",
    "#     # drop rows that became empty after cleaning\n",
    "#     out = out[out[\"self_text\"].str.len() > 0].reset_index(drop=True)\n",
    "#     return out\n",
    "\n",
    "# # ---- run ----\n",
    "# frames = [load_split(DATA_DIR / fname, split) for split, fname in FILES.items()]\n",
    "# df_all = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "# # prepend a local ID\n",
    "# df_all.insert(0, \"local_comment_id\", range(1, len(df_all) + 1))\n",
    "\n",
    "# # enforce final column order and save\n",
    "# df_all = df_all[[\"local_comment_id\", \"self_text\", \"source\", \"real_label\", \"split\"]]\n",
    "# df_all.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "# print(f\"Saved: {OUT_CSV} ({len(df_all):,} rows)\")\n",
    "# print(df_all.groupby([\"split\", \"real_label\"]).size().unstack(fill_value=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e24cb0",
   "metadata": {},
   "source": [
    "At this point we manually added the 'Undefined' comments from the other dataset, adding comment_id to all (fabricated, p=stance has no comment IDs), and re-labels the dataset using an LLM. Prompt is available in `Config.data_tagging_config.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626d58da",
   "metadata": {},
   "source": [
    "# Training Classifier\n",
    "\n",
    "Dataset is assumed to have a new column, `label`, where the `TEST` samples have the real label and the `TRAIN`, `VAL` labels has the LLM created label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdb08c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>local_comment_id</th>\n",
       "      <th>self_text</th>\n",
       "      <th>source</th>\n",
       "      <th>real_label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>You COWARD... you should have been at THE WHIT...</td>\n",
       "      <td>P Stance</td>\n",
       "      <td>Against-Trump</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cool. I trust he requested the same records fo...</td>\n",
       "      <td>P Stance</td>\n",
       "      <td>Against-Trump</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Off your meds again Donnie? You are surrounded...</td>\n",
       "      <td>P Stance</td>\n",
       "      <td>Against-Trump</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>That has to happen anyway. But his profits wil...</td>\n",
       "      <td>P Stance</td>\n",
       "      <td>Against-Trump</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>This is so stupid. Unmasking lets them know wh...</td>\n",
       "      <td>P Stance</td>\n",
       "      <td>Against-Trump</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   local_comment_id                                          self_text  \\\n",
       "0                 1  You COWARD... you should have been at THE WHIT...   \n",
       "1                 2  Cool. I trust he requested the same records fo...   \n",
       "2                 3  Off your meds again Donnie? You are surrounded...   \n",
       "3                 4  That has to happen anyway. But his profits wil...   \n",
       "4                 5  This is so stupid. Unmasking lets them know wh...   \n",
       "\n",
       "     source     real_label  split  \n",
       "0  P Stance  Against-Trump  TRAIN  \n",
       "1  P Stance  Against-Trump  TRAIN  \n",
       "2  P Stance  Against-Trump  TRAIN  \n",
       "3  P Stance  Against-Trump  TRAIN  \n",
       "4  P Stance  Against-Trump  TRAIN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- config ----\n",
    "DATA_DIR = Path(\"Data/p-stance\")\n",
    "OUT_CSV  = DATA_DIR / \"pstance_trump_final.csv\"\n",
    "\n",
    "df = pd.read_csv(OUT_CSV)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
